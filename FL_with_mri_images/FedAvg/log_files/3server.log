2023-09-27 11:08:24.553554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-27 11:08:27.430840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.1/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-11.5/lib64:/opt/minc/1.9.18/lib:/opt/minc/1.9.18/lib/InsightToolkit
2023-09-27 11:08:27.431172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.1/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-11.5/lib64:/opt/minc/1.9.18/lib:/opt/minc/1.9.18/lib/InsightToolkit
2023-09-27 11:08:27.431210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-27 11:10:15.588956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-09-27 11:10:15.595127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.1/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-11.5/lib64:/opt/minc/1.9.18/lib:/opt/minc/1.9.18/lib/InsightToolkit
2023-09-27 11:10:15.596128: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-09-27 11:10:15.596854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO flwr 2023-09-27 11:10:16,432 | app.py:151 | Starting Flower server, config: ServerConfig(num_rounds=10, round_timeout=None)
INFO flwr 2023-09-27 11:10:16,525 | app.py:172 | Flower ECE: gRPC server running (10 rounds), SSL is disabled
INFO flwr 2023-09-27 11:10:16,525 | server.py:86 | Initializing global parameters
INFO flwr 2023-09-27 11:10:16,525 | server.py:269 | Using initial parameters provided by strategy
INFO flwr 2023-09-27 11:10:16,525 | server.py:88 | Evaluating initial parameters
Found  575  nifti files
Matching covariates for loaded files ...
Checking for scans not found in Excel sheet:  0
Covariates data frame size :  (575, 3)
      Age  Sex   FS
958  0.72    1  1.0
959  0.72    0  1.0
960  0.67    1  1.0
961  0.77    1  1.0
962  0.63    1  1.0
Loading files...
Loading file 1 of 575
Loading file 51 of 575
Loading file 101 of 575
Loading file 151 of 575
Loading file 201 of 575
Loading file 251 of 575
Loading file 301 of 575
Loading file 351 of 575
Loading file 401 of 575
Loading file 451 of 575
Loading file 501 of 575
Loading file 551 of 575
Successfully loaded files
Image array size:  (575, 139, 129, 45, 1)
Validation Input shape	: (575, 139, 129, 45, 1)
validation Output shape	: (575, 2)
 1/18 [>.............................] - ETA: 55s 2/18 [==>...........................] - ETA: 40s 3/18 [====>.........................] - ETA: 36s 4/18 [=====>........................] - ETA: 35s 5/18 [=======>......................] - ETA: 33s 6/18 [=========>....................] - ETA: 30s 7/18 [==========>...................] - ETA: 28s 8/18 [============>.................] - ETA: 26s 9/18 [==============>...............] - ETA: 23s10/18 [===============>..............] - ETA: 21s11/18 [=================>............] - ETA: 18s12/18 [===================>..........] - ETA: 16s13/18 [====================>.........] - ETA: 13s14/18 [======================>.......] - ETA: 10s15/18 [========================>.....] - ETA: 8s 16/18 [=========================>....] - ETA: 5s17/18 [===========================>..] - ETA: 2s18/18 [==============================] - ETA: 0s18/18 [==============================] - 50s 3s/step
fpr: [[0.0, 0.004016064257028112, 0.004016064257028112, 0.008032128514056224, 0.008032128514056224, 0.012048192771084338, 0.012048192771084338, 0.04417670682730924, 0.04417670682730924, 0.060240963855421686, 0.060240963855421686, 0.0642570281124498, 0.0642570281124498, 0.06827309236947791, 0.06827309236947791, 0.08032128514056225, 0.08032128514056225, 0.08835341365461848, 0.08835341365461848, 0.09236947791164658, 0.09236947791164658, 0.10040160642570281, 0.10040160642570281, 0.10843373493975904, 0.10843373493975904, 0.11244979919678715, 0.11244979919678715, 0.11646586345381527, 0.11646586345381527, 0.12449799196787148, 0.12449799196787148, 0.1285140562248996, 0.1285140562248996, 0.1566265060240964, 0.1566265060240964, 0.1646586345381526, 0.1646586345381526, 0.18072289156626506, 0.18072289156626506, 0.18473895582329317, 0.18473895582329317, 0.19678714859437751, 0.19678714859437751, 0.20080321285140562, 0.20080321285140562, 0.20883534136546184, 0.20883534136546184, 0.21686746987951808, 0.21686746987951808, 0.2289156626506024, 0.2289156626506024, 0.23293172690763053, 0.23293172690763053, 0.23694779116465864, 0.23694779116465864, 0.24096385542168675, 0.24096385542168675, 0.2570281124497992, 0.2570281124497992, 0.26104417670682734, 0.26104417670682734, 0.26907630522088355, 0.26907630522088355, 0.27710843373493976, 0.27710843373493976, 0.28112449799196787, 0.28112449799196787, 0.285140562248996, 0.285140562248996, 0.2891566265060241, 0.2891566265060241, 0.2931726907630522, 0.2931726907630522, 0.30522088353413657, 0.30522088353413657, 0.3092369477911647, 0.3092369477911647, 0.3172690763052209, 0.3172690763052209, 0.3293172690763052, 0.3293172690763052, 0.3333333333333333, 0.3333333333333333, 0.3373493975903614, 0.3373493975903614, 0.3413654618473896, 0.3413654618473896, 0.3453815261044177, 0.3453815261044177, 0.3493975903614458, 0.3493975903614458, 0.3654618473895582, 0.3654618473895582, 0.37751004016064255, 0.37751004016064255, 0.3815261044176707, 0.3815261044176707, 0.3895582329317269, 0.3895582329317269, 0.39759036144578314, 0.39759036144578314, 0.40160642570281124, 0.40160642570281124, 0.41365461847389556, 0.41365461847389556, 0.42570281124497994, 0.42570281124497994, 0.42971887550200805, 0.42971887550200805, 0.43373493975903615, 0.43373493975903615, 0.43775100401606426, 0.43775100401606426, 0.44176706827309237, 0.44176706827309237, 0.4457831325301205, 0.4457831325301205, 0.4497991967871486, 0.4497991967871486, 0.4538152610441767, 0.4538152610441767, 0.4578313253012048, 0.4578313253012048, 0.46184738955823296, 0.46184738955823296, 0.46586345381526106, 0.46586345381526106, 0.4738955823293173, 0.4738955823293173, 0.4819277108433735, 0.4819277108433735, 0.4899598393574297, 0.4899598393574297, 0.4939759036144578, 0.4939759036144578, 0.4979919678714859, 0.4979919678714859, 0.5020080321285141, 0.5020080321285141, 0.5060240963855421, 0.5060240963855421, 0.5100401606425703, 0.5100401606425703, 0.5220883534136547, 0.5220883534136547, 0.5261044176706827, 0.5261044176706827, 0.5301204819277109, 0.5301204819277109, 0.5381526104417671, 0.5381526104417671, 0.5502008032128514, 0.5502008032128514, 0.5542168674698795, 0.5542168674698795, 0.5582329317269076, 0.5582329317269076, 0.5662650602409639, 0.5662650602409639, 0.5742971887550201, 0.5742971887550201, 0.5863453815261044, 0.5863453815261044, 0.5903614457831325, 0.5903614457831325, 0.5943775100401606, 0.5943775100401606, 0.606425702811245, 0.606425702811245, 0.6184738955823293, 0.6184738955823293, 0.6224899598393574, 0.6224899598393574, 0.6305220883534136, 0.6305220883534136, 0.6385542168674698, 0.6385542168674698, 0.6465863453815262, 0.6465863453815262, 0.6546184738955824, 0.6546184738955824, 0.6827309236947792, 0.6827309236947792, 0.6867469879518072, 0.6867469879518072, 0.6907630522088354, 0.6907630522088354, 0.6947791164658634, 0.6947791164658634, 0.7028112449799196, 0.7028112449799196, 0.7068273092369478, 0.7068273092369478, 0.7108433734939759, 0.7108433734939759, 0.7188755020080321, 0.7188755020080321, 0.7228915662650602, 0.7228915662650602, 0.7309236947791165, 0.7309236947791165, 0.7349397590361446, 0.7349397590361446, 0.7429718875502008, 0.7429718875502008, 0.7469879518072289, 0.7469879518072289, 0.751004016064257, 0.751004016064257, 0.7550200803212851, 0.7550200803212851, 0.7590361445783133, 0.7590361445783133, 0.7630522088353414, 0.7630522088353414, 0.7670682730923695, 0.7670682730923695, 0.7710843373493976, 0.7710843373493976, 0.7791164658634538, 0.7791164658634538, 0.7831325301204819, 0.7831325301204819, 0.7871485943775101, 0.7871485943775101, 0.8072289156626506, 0.8072289156626506, 0.8232931726907631, 0.8232931726907631, 0.8273092369477911, 0.8273092369477911, 0.8313253012048193, 0.8313253012048193, 0.8353413654618473, 0.8353413654618473, 0.8433734939759037, 0.8433734939759037, 0.8473895582329317, 0.8473895582329317, 0.8514056224899599, 0.8514056224899599, 0.8554216867469879, 0.8554216867469879, 0.8594377510040161, 0.8594377510040161, 0.8634538152610441, 0.8634538152610441, 0.8674698795180723, 0.8674698795180723, 0.8714859437751004, 0.8714859437751004, 0.8755020080321285, 0.8755020080321285, 0.8835341365461847, 0.8835341365461847, 0.891566265060241, 0.891566265060241, 0.8955823293172691, 0.8955823293172691, 0.9036144578313253, 0.9036144578313253, 0.9076305220883534, 0.9076305220883534, 0.9156626506024096, 0.9156626506024096, 0.9196787148594378, 0.9196787148594378, 0.9236947791164659, 0.9236947791164659, 0.927710843373494, 0.927710843373494, 0.9317269076305221, 0.9317269076305221, 0.9357429718875502, 0.9357429718875502, 0.9437751004016064, 0.9437751004016064, 0.9518072289156626, 0.9518072289156626, 0.9598393574297188, 0.9598393574297188, 0.963855421686747, 0.963855421686747, 0.9678714859437751, 0.9678714859437751, 0.9759036144578314, 0.9759036144578314, 0.9799196787148594, 0.9799196787148594, 0.9839357429718876, 0.9839357429718876, 0.9879518072289156, 0.9879518072289156, 0.9919678714859438, 0.9919678714859438, 1.0, 1.0], [0.0, 0.003067484662576687, 0.012269938650306749, 0.012269938650306749, 0.027607361963190184, 0.027607361963190184, 0.03374233128834356, 0.03374233128834356, 0.03680981595092025, 0.03680981595092025, 0.05214723926380368, 0.05214723926380368, 0.06748466257668712, 0.06748466257668712, 0.07668711656441718, 0.07668711656441718, 0.07975460122699386, 0.07975460122699386, 0.08588957055214724, 0.08588957055214724, 0.09202453987730061, 0.09202453987730061, 0.09815950920245399, 0.09815950920245399, 0.10122699386503067, 0.10122699386503067, 0.10429447852760736, 0.10429447852760736, 0.10736196319018405, 0.10736196319018405, 0.11042944785276074, 0.11042944785276074, 0.11349693251533742, 0.11349693251533742, 0.1165644171779141, 0.1165644171779141, 0.12269938650306748, 0.12269938650306748, 0.13190184049079753, 0.13190184049079753, 0.1441717791411043, 0.1441717791411043, 0.15950920245398773, 0.15950920245398773, 0.17484662576687116, 0.17484662576687116, 0.18098159509202455, 0.18098159509202455, 0.18404907975460122, 0.18404907975460122, 0.1901840490797546, 0.1901840490797546, 0.19631901840490798, 0.19631901840490798, 0.20245398773006135, 0.20245398773006135, 0.20552147239263804, 0.20552147239263804, 0.22085889570552147, 0.22085889570552147, 0.2331288343558282, 0.2331288343558282, 0.24846625766871167, 0.24846625766871167, 0.25766871165644173, 0.25766871165644173, 0.2668711656441718, 0.2668711656441718, 0.27607361963190186, 0.27607361963190186, 0.2852760736196319, 0.2852760736196319, 0.29754601226993865, 0.29754601226993865, 0.30368098159509205, 0.30368098159509205, 0.3098159509202454, 0.3098159509202454, 0.3159509202453988, 0.3159509202453988, 0.3312883435582822, 0.3312883435582822, 0.3343558282208589, 0.3343558282208589, 0.34049079754601225, 0.34049079754601225, 0.34355828220858897, 0.34355828220858897, 0.34662576687116564, 0.34662576687116564, 0.3558282208588957, 0.3558282208588957, 0.3588957055214724, 0.3588957055214724, 0.37116564417177916, 0.37116564417177916, 0.37423312883435583, 0.37423312883435583, 0.3803680981595092, 0.3803680981595092, 0.38650306748466257, 0.38650306748466257, 0.3895705521472393, 0.3895705521472393, 0.39263803680981596, 0.39263803680981596, 0.39570552147239263, 0.39570552147239263, 0.3987730061349693, 0.3987730061349693, 0.40797546012269936, 0.40797546012269936, 0.4110429447852761, 0.4110429447852761, 0.43558282208588955, 0.43558282208588955, 0.44785276073619634, 0.44785276073619634, 0.4570552147239264, 0.4570552147239264, 0.4662576687116564, 0.4662576687116564, 0.4723926380368098, 0.4723926380368098, 0.4785276073619632, 0.4785276073619632, 0.4815950920245399, 0.4815950920245399, 0.48466257668711654, 0.48466257668711654, 0.50920245398773, 0.50920245398773, 0.5153374233128835, 0.5153374233128835, 0.5276073619631901, 0.5276073619631901, 0.5306748466257669, 0.5306748466257669, 0.5337423312883436, 0.5337423312883436, 0.5368098159509203, 0.5368098159509203, 0.5398773006134969, 0.5398773006134969, 0.5429447852760736, 0.5429447852760736, 0.5644171779141104, 0.5644171779141104, 0.5766871165644172, 0.5766871165644172, 0.5797546012269938, 0.5797546012269938, 0.5950920245398773, 0.5950920245398773, 0.6042944785276073, 0.6042944785276073, 0.6196319018404908, 0.6196319018404908, 0.6257668711656442, 0.6257668711656442, 0.6288343558282209, 0.6288343558282209, 0.6380368098159509, 0.6380368098159509, 0.6411042944785276, 0.6411042944785276, 0.6441717791411042, 0.6441717791411042, 0.647239263803681, 0.647239263803681, 0.656441717791411, 0.656441717791411, 0.6656441717791411, 0.6656441717791411, 0.6687116564417178, 0.6687116564417178, 0.6840490797546013, 0.6840490797546013, 0.6901840490797546, 0.6901840490797546, 0.696319018404908, 0.696319018404908, 0.6993865030674846, 0.6993865030674846, 0.7085889570552147, 0.7085889570552147, 0.7116564417177914, 0.7116564417177914, 0.7147239263803681, 0.7147239263803681, 0.7208588957055214, 0.7208588957055214, 0.7239263803680982, 0.7239263803680982, 0.7300613496932515, 0.7300613496932515, 0.7361963190184049, 0.7361963190184049, 0.745398773006135, 0.745398773006135, 0.7515337423312883, 0.7515337423312883, 0.754601226993865, 0.754601226993865, 0.7576687116564417, 0.7576687116564417, 0.7607361963190185, 0.7607361963190185, 0.7668711656441718, 0.7668711656441718, 0.7730061349693251, 0.7730061349693251, 0.7760736196319018, 0.7760736196319018, 0.7791411042944786, 0.7822085889570553, 0.7822085889570553, 0.7852760736196319, 0.7852760736196319, 0.7883435582822086, 0.7883435582822086, 0.7944785276073619, 0.7944785276073619, 0.7975460122699386, 0.7975460122699386, 0.8067484662576687, 0.8067484662576687, 0.8220858895705522, 0.8220858895705522, 0.8251533742331288, 0.8251533742331288, 0.8312883435582822, 0.8312883435582822, 0.8404907975460123, 0.8404907975460123, 0.843558282208589, 0.843558282208589, 0.8466257668711656, 0.8466257668711656, 0.8496932515337423, 0.8496932515337423, 0.8558282208588958, 0.8558282208588958, 0.8588957055214724, 0.8588957055214724, 0.8619631901840491, 0.8619631901840491, 0.8650306748466258, 0.8650306748466258, 0.8680981595092024, 0.8680981595092024, 0.8711656441717791, 0.8711656441717791, 0.8773006134969326, 0.8803680981595092, 0.8803680981595092, 0.8926380368098159, 0.8926380368098159, 0.8987730061349694, 0.8987730061349694, 0.911042944785276, 0.911042944785276, 0.9141104294478528, 0.9141104294478528, 0.9202453987730062, 0.9202453987730062, 0.9233128834355828, 0.9233128834355828, 0.9263803680981595, 0.9263803680981595, 0.9355828220858896, 0.9355828220858896, 0.9386503067484663, 0.9386503067484663, 0.941717791411043, 0.941717791411043, 0.9447852760736196, 0.9447852760736196, 0.9539877300613497, 0.9539877300613497, 0.9570552147239264, 0.9570552147239264, 0.9662576687116564, 0.9662576687116564, 0.9693251533742331, 0.9693251533742331, 0.9723926380368099, 0.9723926380368099, 0.9754601226993865, 0.9754601226993865, 0.9785276073619632, 0.9785276073619632, 0.9815950920245399, 0.9815950920245399, 0.9846625766871165, 0.9846625766871165, 1.0, 1.0]]
tpr: [[0.0, 0.0, 0.015337423312883436, 0.015337423312883436, 0.018404907975460124, 0.018404907975460124, 0.02147239263803681, 0.02147239263803681, 0.024539877300613498, 0.024539877300613498, 0.027607361963190184, 0.027607361963190184, 0.03067484662576687, 0.03067484662576687, 0.03374233128834356, 0.03374233128834356, 0.04294478527607362, 0.04294478527607362, 0.046012269938650305, 0.046012269938650305, 0.05521472392638037, 0.05521472392638037, 0.05828220858895705, 0.05828220858895705, 0.06134969325153374, 0.06134969325153374, 0.06441717791411043, 0.06441717791411043, 0.0736196319018405, 0.0736196319018405, 0.07668711656441718, 0.07668711656441718, 0.07975460122699386, 0.07975460122699386, 0.08588957055214724, 0.08588957055214724, 0.08895705521472393, 0.08895705521472393, 0.10122699386503067, 0.10122699386503067, 0.10736196319018405, 0.10736196319018405, 0.1196319018404908, 0.1196319018404908, 0.12883435582822086, 0.12883435582822086, 0.13190184049079753, 0.13190184049079753, 0.13496932515337423, 0.13496932515337423, 0.13803680981595093, 0.13803680981595093, 0.1411042944785276, 0.1411042944785276, 0.1441717791411043, 0.1441717791411043, 0.15030674846625766, 0.15030674846625766, 0.15337423312883436, 0.15337423312883436, 0.15644171779141106, 0.15644171779141106, 0.15950920245398773, 0.15950920245398773, 0.1687116564417178, 0.1687116564417178, 0.17484662576687116, 0.17484662576687116, 0.17791411042944785, 0.17791411042944785, 0.19325153374233128, 0.19325153374233128, 0.20245398773006135, 0.20245398773006135, 0.20552147239263804, 0.20552147239263804, 0.2116564417177914, 0.2116564417177914, 0.2147239263803681, 0.2147239263803681, 0.21779141104294478, 0.21779141104294478, 0.22085889570552147, 0.22085889570552147, 0.22392638036809817, 0.22392638036809817, 0.22699386503067484, 0.22699386503067484, 0.2331288343558282, 0.2331288343558282, 0.2392638036809816, 0.2392638036809816, 0.24233128834355827, 0.24233128834355827, 0.24539877300613497, 0.24539877300613497, 0.24846625766871167, 0.24846625766871167, 0.254601226993865, 0.254601226993865, 0.26380368098159507, 0.26380368098159507, 0.26993865030674846, 0.26993865030674846, 0.27607361963190186, 0.27607361963190186, 0.2791411042944785, 0.2791411042944785, 0.2852760736196319, 0.2852760736196319, 0.2883435582822086, 0.2883435582822086, 0.29141104294478526, 0.29141104294478526, 0.3006134969325153, 0.3006134969325153, 0.30368098159509205, 0.30368098159509205, 0.3098159509202454, 0.3098159509202454, 0.3159509202453988, 0.3159509202453988, 0.3312883435582822, 0.3312883435582822, 0.3343558282208589, 0.3343558282208589, 0.34355828220858897, 0.34355828220858897, 0.35276073619631904, 0.35276073619631904, 0.3558282208588957, 0.3558282208588957, 0.3588957055214724, 0.3588957055214724, 0.3619631901840491, 0.3619631901840491, 0.37116564417177916, 0.37116564417177916, 0.37423312883435583, 0.37423312883435583, 0.3803680981595092, 0.3803680981595092, 0.39570552147239263, 0.39570552147239263, 0.4049079754601227, 0.4049079754601227, 0.42024539877300615, 0.42024539877300615, 0.4233128834355828, 0.4233128834355828, 0.43558282208588955, 0.43558282208588955, 0.4570552147239264, 0.4570552147239264, 0.4601226993865031, 0.4601226993865031, 0.46319018404907975, 0.46319018404907975, 0.4662576687116564, 0.4662576687116564, 0.46932515337423314, 0.46932515337423314, 0.4723926380368098, 0.4723926380368098, 0.48466257668711654, 0.48466257668711654, 0.49079754601226994, 0.49079754601226994, 0.5153374233128835, 0.5153374233128835, 0.5184049079754601, 0.5184049079754601, 0.5214723926380368, 0.5214723926380368, 0.5276073619631901, 0.5276073619631901, 0.5337423312883436, 0.5337423312883436, 0.5429447852760736, 0.5429447852760736, 0.5521472392638037, 0.5521472392638037, 0.5644171779141104, 0.5644171779141104, 0.588957055214724, 0.588957055214724, 0.5920245398773006, 0.5920245398773006, 0.6012269938650306, 0.6012269938650306, 0.6042944785276073, 0.6042944785276073, 0.6073619631901841, 0.6073619631901841, 0.6104294478527608, 0.6104294478527608, 0.6134969325153374, 0.6134969325153374, 0.6196319018404908, 0.6196319018404908, 0.6257668711656442, 0.6257668711656442, 0.6288343558282209, 0.6288343558282209, 0.6411042944785276, 0.6411042944785276, 0.6441717791411042, 0.6441717791411042, 0.6533742331288344, 0.6533742331288344, 0.656441717791411, 0.656441717791411, 0.6595092024539877, 0.6595092024539877, 0.6656441717791411, 0.6656441717791411, 0.6687116564417178, 0.6687116564417178, 0.6840490797546013, 0.6840490797546013, 0.6901840490797546, 0.6901840490797546, 0.696319018404908, 0.696319018404908, 0.7024539877300614, 0.7024539877300614, 0.7147239263803681, 0.7147239263803681, 0.7239263803680982, 0.7239263803680982, 0.7331288343558282, 0.7331288343558282, 0.7423312883435583, 0.7423312883435583, 0.7515337423312883, 0.7515337423312883, 0.7668711656441718, 0.7668711656441718, 0.7791411042944786, 0.7791411042944786, 0.7944785276073619, 0.7944785276073619, 0.7975460122699386, 0.7975460122699386, 0.803680981595092, 0.803680981595092, 0.8098159509202454, 0.8098159509202454, 0.8159509202453987, 0.8159509202453987, 0.8190184049079755, 0.8190184049079755, 0.8251533742331288, 0.8251533742331288, 0.8404907975460123, 0.8404907975460123, 0.8558282208588958, 0.8558282208588958, 0.8680981595092024, 0.8680981595092024, 0.8773006134969326, 0.8773006134969326, 0.8834355828220859, 0.8834355828220859, 0.8865030674846626, 0.8865030674846626, 0.8895705521472392, 0.8895705521472392, 0.8926380368098159, 0.8926380368098159, 0.8957055214723927, 0.8957055214723927, 0.8987730061349694, 0.8987730061349694, 0.901840490797546, 0.901840490797546, 0.9079754601226994, 0.9079754601226994, 0.9141104294478528, 0.9141104294478528, 0.9202453987730062, 0.9202453987730062, 0.9233128834355828, 0.9233128834355828, 0.9325153374233128, 0.9325153374233128, 0.9478527607361963, 0.9478527607361963, 0.9631901840490797, 0.9631901840490797, 0.9662576687116564, 0.9662576687116564, 0.9723926380368099, 0.9723926380368099, 0.9877300613496932, 0.9877300613496932, 1.0], [0.0, 0.0, 0.0, 0.008032128514056224, 0.008032128514056224, 0.012048192771084338, 0.012048192771084338, 0.01606425702811245, 0.01606425702811245, 0.020080321285140562, 0.020080321285140562, 0.024096385542168676, 0.024096385542168676, 0.0321285140562249, 0.0321285140562249, 0.03614457831325301, 0.03614457831325301, 0.040160642570281124, 0.040160642570281124, 0.04819277108433735, 0.04819277108433735, 0.05622489959839357, 0.05622489959839357, 0.0642570281124498, 0.0642570281124498, 0.06827309236947791, 0.06827309236947791, 0.07228915662650602, 0.07228915662650602, 0.07630522088353414, 0.07630522088353414, 0.08032128514056225, 0.08032128514056225, 0.08433734939759036, 0.08433734939759036, 0.09236947791164658, 0.09236947791164658, 0.0963855421686747, 0.0963855421686747, 0.10441767068273092, 0.10441767068273092, 0.10843373493975904, 0.10843373493975904, 0.11646586345381527, 0.11646586345381527, 0.12449799196787148, 0.12449799196787148, 0.1285140562248996, 0.1285140562248996, 0.13253012048192772, 0.13253012048192772, 0.13654618473895583, 0.13654618473895583, 0.14056224899598393, 0.14056224899598393, 0.14457831325301204, 0.14457831325301204, 0.14859437751004015, 0.14859437751004015, 0.15261044176706828, 0.15261044176706828, 0.1566265060240964, 0.1566265060240964, 0.1646586345381526, 0.1646586345381526, 0.1686746987951807, 0.1686746987951807, 0.17269076305220885, 0.17269076305220885, 0.17670682730923695, 0.17670682730923695, 0.1927710843373494, 0.1927710843373494, 0.21285140562248997, 0.21285140562248997, 0.21686746987951808, 0.21686746987951808, 0.22088353413654618, 0.22088353413654618, 0.2289156626506024, 0.2289156626506024, 0.23293172690763053, 0.23293172690763053, 0.23694779116465864, 0.23694779116465864, 0.24096385542168675, 0.24096385542168675, 0.24497991967871485, 0.24497991967871485, 0.24899598393574296, 0.24899598393574296, 0.25301204819277107, 0.25301204819277107, 0.2570281124497992, 0.2570281124497992, 0.26506024096385544, 0.26506024096385544, 0.26907630522088355, 0.26907630522088355, 0.27710843373493976, 0.27710843373493976, 0.28112449799196787, 0.28112449799196787, 0.2891566265060241, 0.2891566265060241, 0.2931726907630522, 0.2931726907630522, 0.2971887550200803, 0.2971887550200803, 0.30522088353413657, 0.30522088353413657, 0.3092369477911647, 0.3092369477911647, 0.3132530120481928, 0.3132530120481928, 0.3172690763052209, 0.3172690763052209, 0.3453815261044177, 0.3453815261044177, 0.3534136546184739, 0.3534136546184739, 0.3614457831325301, 0.3614457831325301, 0.36947791164658633, 0.36947791164658633, 0.37751004016064255, 0.37751004016064255, 0.3815261044176707, 0.3815261044176707, 0.39357429718875503, 0.39357429718875503, 0.40562248995983935, 0.40562248995983935, 0.40963855421686746, 0.40963855421686746, 0.41365461847389556, 0.41365461847389556, 0.42570281124497994, 0.42570281124497994, 0.43373493975903615, 0.43373493975903615, 0.44176706827309237, 0.44176706827309237, 0.4457831325301205, 0.4457831325301205, 0.4497991967871486, 0.4497991967871486, 0.46184738955823296, 0.46184738955823296, 0.46987951807228917, 0.46987951807228917, 0.4738955823293173, 0.4738955823293173, 0.4779116465863454, 0.4779116465863454, 0.4899598393574297, 0.4899598393574297, 0.4939759036144578, 0.4939759036144578, 0.4979919678714859, 0.4979919678714859, 0.5020080321285141, 0.5020080321285141, 0.5060240963855421, 0.5060240963855421, 0.5100401606425703, 0.5100401606425703, 0.5180722891566265, 0.5180722891566265, 0.5261044176706827, 0.5261044176706827, 0.5341365461847389, 0.5341365461847389, 0.5381526104417671, 0.5381526104417671, 0.5421686746987951, 0.5421686746987951, 0.5461847389558233, 0.5461847389558233, 0.5502008032128514, 0.5502008032128514, 0.5542168674698795, 0.5542168674698795, 0.5582329317269076, 0.5582329317269076, 0.5622489959839357, 0.5622489959839357, 0.5662650602409639, 0.5662650602409639, 0.570281124497992, 0.570281124497992, 0.5742971887550201, 0.5742971887550201, 0.5863453815261044, 0.5863453815261044, 0.5983935742971888, 0.5983935742971888, 0.6024096385542169, 0.6024096385542169, 0.6104417670682731, 0.6104417670682731, 0.6184738955823293, 0.6184738955823293, 0.6224899598393574, 0.6224899598393574, 0.6345381526104418, 0.6345381526104418, 0.6506024096385542, 0.6506024096385542, 0.6546184738955824, 0.6546184738955824, 0.6586345381526104, 0.6586345381526104, 0.6626506024096386, 0.6626506024096386, 0.6666666666666666, 0.6706827309236948, 0.6706827309236948, 0.6827309236947792, 0.6827309236947792, 0.6907630522088354, 0.6907630522088354, 0.6947791164658634, 0.6947791164658634, 0.7068273092369478, 0.7068273092369478, 0.7108433734939759, 0.7108433734939759, 0.714859437751004, 0.714859437751004, 0.7188755020080321, 0.7188755020080321, 0.7228915662650602, 0.7228915662650602, 0.7309236947791165, 0.7309236947791165, 0.7389558232931727, 0.7389558232931727, 0.7429718875502008, 0.7429718875502008, 0.7590361445783133, 0.7590361445783133, 0.7630522088353414, 0.7630522088353414, 0.7670682730923695, 0.7670682730923695, 0.7710843373493976, 0.7710843373493976, 0.7831325301204819, 0.7831325301204819, 0.7911646586345381, 0.7911646586345381, 0.7991967871485943, 0.7991967871485943, 0.7991967871485943, 0.8032128514056225, 0.8032128514056225, 0.8152610441767069, 0.8152610441767069, 0.8192771084337349, 0.8192771084337349, 0.8353413654618473, 0.8353413654618473, 0.8433734939759037, 0.8433734939759037, 0.8714859437751004, 0.8714859437751004, 0.8755020080321285, 0.8755020080321285, 0.8835341365461847, 0.8835341365461847, 0.8875502008032129, 0.8875502008032129, 0.891566265060241, 0.891566265060241, 0.8995983935742972, 0.8995983935742972, 0.9076305220883534, 0.9076305220883534, 0.9116465863453815, 0.9116465863453815, 0.9196787148594378, 0.9196787148594378, 0.9317269076305221, 0.9317269076305221, 0.9357429718875502, 0.9357429718875502, 0.9397590361445783, 0.9397590361445783, 0.9558232931726908, 0.9558232931726908, 0.9879518072289156, 0.9879518072289156, 0.9919678714859438, 0.9919678714859438, 0.9959839357429718, 0.9959839357429718, 1.0]]
roc_auc: [0.4135560647497967, 0.41354990514204054]
Round 0 - y_pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Round 0 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[  0 326]
 [  0 249]]
Precision: 0.1875
Recall: 0.4330
F1 score: 0.2617
 1/18 [>.............................] - ETA: 49s - loss: 0.8160 - accuracy: 0.2500 2/18 [==>...........................] - ETA: 34s - loss: 0.8306 - accuracy: 0.2188 3/18 [====>.........................] - ETA: 32s - loss: 0.8346 - accuracy: 0.2083 4/18 [=====>........................] - ETA: 29s - loss: 0.8501 - accuracy: 0.1719 5/18 [=======>......................] - ETA: 27s - loss: 0.8290 - accuracy: 0.2250 6/18 [=========>....................] - ETA: 24s - loss: 0.8330 - accuracy: 0.2135 7/18 [==========>...................] - ETA: 23s - loss: 0.8309 - accuracy: 0.2188 8/18 [============>.................] - ETA: 21s - loss: 0.8241 - accuracy: 0.2344 9/18 [==============>...............] - ETA: 19s - loss: 0.8222 - accuracy: 0.236110/18 [===============>..............] - ETA: 17s - loss: 0.8231 - accuracy: 0.234411/18 [=================>............] - ETA: 15s - loss: 0.8240 - accuracy: 0.233012/18 [===================>..........] - ETA: 13s - loss: 0.8180 - accuracy: 0.247413/18 [====================>.........] - ETA: 11s - loss: 0.8016 - accuracy: 0.288514/18 [======================>.......] - ETA: 9s - loss: 0.7847 - accuracy: 0.3304 15/18 [========================>.....] - ETA: 7s - loss: 0.7708 - accuracy: 0.364616/18 [=========================>....] - ETA: 4s - loss: 0.7595 - accuracy: 0.392617/18 [===========================>..] - ETA: 2s - loss: 0.7527 - accuracy: 0.409918/18 [==============================] - ETA: 0s - loss: 0.7434 - accuracy: 0.433018/18 [==============================] - 44s 2s/step - loss: 0.7434 - accuracy: 0.4330
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-27 11:12:26,118 | server.py:95 | initial parameters (loss, other metrics): 0.7433564066886902, {'accuracy': 0.4330434799194336}
INFO flwr 2023-09-27 11:12:26,119 | server.py:101 | FL starting
DEBUG flwr 2023-09-27 11:12:52,460 | server.py:223 | fit_round 1: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 13:40:33,637 | server.py:237 | fit_round 1 received 4 results and 0 failures
WARNING flwr 2023-09-27 13:40:33,689 | fedavg.py:243 | No fit_metrics_aggregation_fn provided
Round 0 evaluation completed
 1/18 [>.............................] - ETA: 44s 2/18 [==>...........................] - ETA: 27s 3/18 [====>.........................] - ETA: 24s 4/18 [=====>........................] - ETA: 21s 5/18 [=======>......................] - ETA: 20s 6/18 [=========>....................] - ETA: 17s 7/18 [==========>...................] - ETA: 16s 8/18 [============>.................] - ETA: 15s 9/18 [==============>...............] - ETA: 14s10/18 [===============>..............] - ETA: 12s11/18 [=================>............] - ETA: 11s12/18 [===================>..........] - ETA: 9s 13/18 [====================>.........] - ETA: 7s14/18 [======================>.......] - ETA: 6s15/18 [========================>.....] - ETA: 4s16/18 [=========================>....] - ETA: 3s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 29s 2s/step
fpr: [[0.0, 1.0], [0.0, 0.003067484662576687, 1.0]]
tpr: [[0.0, 1.0], [0.0, 0.024096385542168676, 1.0]]
roc_auc: [0.5, 0.510514450439796]
Round 1 - y_pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Round 1 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[  0 326]
 [  0 249]]
Precision: 0.1875
Recall: 0.4330
F1 score: 0.2617
 1/18 [>.............................] - ETA: 36s - loss: 436.0469 - accuracy: 0.2500 2/18 [==>...........................] - ETA: 24s - loss: 452.0190 - accuracy: 0.2188 3/18 [====>.........................] - ETA: 22s - loss: 459.2034 - accuracy: 0.2083 4/18 [=====>........................] - ETA: 21s - loss: 480.0889 - accuracy: 0.1719 5/18 [=======>......................] - ETA: 20s - loss: 448.5041 - accuracy: 0.2250 6/18 [=========>....................] - ETA: 18s - loss: 454.9696 - accuracy: 0.2135 7/18 [==========>...................] - ETA: 17s - loss: 452.6963 - accuracy: 0.2188 8/18 [============>.................] - ETA: 15s - loss: 444.7812 - accuracy: 0.2344 9/18 [==============>...............] - ETA: 13s - loss: 443.8451 - accuracy: 0.236110/18 [===============>..............] - ETA: 12s - loss: 444.2868 - accuracy: 0.234411/18 [=================>............] - ETA: 10s - loss: 445.0151 - accuracy: 0.233012/18 [===================>..........] - ETA: 9s - loss: 437.0757 - accuracy: 0.2474 13/18 [====================>.........] - ETA: 7s - loss: 413.0778 - accuracy: 0.288514/18 [======================>.......] - ETA: 6s - loss: 388.6778 - accuracy: 0.330415/18 [========================>.....] - ETA: 4s - loss: 368.6524 - accuracy: 0.364616/18 [=========================>....] - ETA: 3s - loss: 352.1807 - accuracy: 0.392617/18 [===========================>..] - ETA: 1s - loss: 342.2255 - accuracy: 0.409918/18 [==============================] - ETA: 0s - loss: 328.8216 - accuracy: 0.433018/18 [==============================] - 31s 2s/step - loss: 328.8216 - accuracy: 0.4330
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-27 13:41:37,475 | server.py:125 | fit progress: (1, 328.82159423828125, {'accuracy': 0.4330434799194336}, 8951.355709106196)
DEBUG flwr 2023-09-27 13:41:37,477 | server.py:173 | evaluate_round 1: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 13:41:55,115 | server.py:187 | evaluate_round 1 received 4 results and 0 failures
WARNING flwr 2023-09-27 13:41:55,116 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-09-27 13:41:55,116 | server.py:223 | fit_round 2: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 16:14:18,392 | server.py:237 | fit_round 2 received 4 results and 0 failures
Round 1 evaluation completed
 1/18 [>.............................] - ETA: 59s 2/18 [==>...........................] - ETA: 49s 3/18 [====>.........................] - ETA: 53s 4/18 [=====>........................] - ETA: 48s 5/18 [=======>......................] - ETA: 44s 6/18 [=========>....................] - ETA: 40s 7/18 [==========>...................] - ETA: 37s 8/18 [============>.................] - ETA: 33s 9/18 [==============>...............] - ETA: 30s10/18 [===============>..............] - ETA: 26s11/18 [=================>............] - ETA: 23s12/18 [===================>..........] - ETA: 20s13/18 [====================>.........] - ETA: 16s14/18 [======================>.......] - ETA: 13s15/18 [========================>.....] - ETA: 9s 16/18 [=========================>....] - ETA: 6s17/18 [===========================>..] - ETA: 3s18/18 [==============================] - ETA: 0s18/18 [==============================] - 60s 3s/step
fpr: [[0.0, 0.024096385542168676, 1.0], [0.0, 1.0]]
tpr: [[0.0, 0.003067484662576687, 1.0], [0.0, 1.0]]
roc_auc: [0.489485549560204, 0.5]
Round 2 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 2 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 1:46 - loss: 5528.1758 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 1:06 - loss: 4909.1548 - accuracy: 0.7812 3/18 [====>.........................] - ETA: 1:05 - loss: 4751.3447 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 1:00 - loss: 3914.0198 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 56s - loss: 5050.9229 - accuracy: 0.7750  6/18 [=========>....................] - ETA: 52s - loss: 4808.4038 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 48s - loss: 4924.6226 - accuracy: 0.7812 8/18 [============>.................] - ETA: 44s - loss: 5292.0859 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 39s - loss: 5343.0181 - accuracy: 0.763910/18 [===============>..............] - ETA: 35s - loss: 5290.0400 - accuracy: 0.765611/18 [=================>............] - ETA: 30s - loss: 5276.1411 - accuracy: 0.767012/18 [===================>..........] - ETA: 26s - loss: 5604.2251 - accuracy: 0.752613/18 [====================>.........] - ETA: 21s - loss: 6511.2744 - accuracy: 0.711514/18 [======================>.......] - ETA: 17s - loss: 7443.3125 - accuracy: 0.669615/18 [========================>.....] - ETA: 12s - loss: 8224.2168 - accuracy: 0.635416/18 [=========================>....] - ETA: 8s - loss: 8851.8291 - accuracy: 0.6074 17/18 [===========================>..] - ETA: 4s - loss: 9221.2422 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 9732.5850 - accuracy: 0.567018/18 [==============================] - 75s 4s/step - loss: 9732.5850 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-27 16:17:08,427 | server.py:125 | fit progress: (2, 9732.5849609375, {'accuracy': 0.5669565200805664}, 18282.308472028933)
DEBUG flwr 2023-09-27 16:17:08,428 | server.py:173 | evaluate_round 2: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 16:17:34,556 | server.py:187 | evaluate_round 2 received 4 results and 0 failures
DEBUG flwr 2023-09-27 16:17:34,557 | server.py:223 | fit_round 3: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 19:09:30,228 | server.py:237 | fit_round 3 received 4 results and 0 failures
Round 2 evaluation completed
 1/18 [>.............................] - ETA: 32s 2/18 [==>...........................] - ETA: 26s 3/18 [====>.........................] - ETA: 25s 4/18 [=====>........................] - ETA: 25s 5/18 [=======>......................] - ETA: 23s 6/18 [=========>....................] - ETA: 21s 7/18 [==========>...................] - ETA: 19s 8/18 [============>.................] - ETA: 17s 9/18 [==============>...............] - ETA: 15s10/18 [===============>..............] - ETA: 14s11/18 [=================>............] - ETA: 12s12/18 [===================>..........] - ETA: 11s13/18 [====================>.........] - ETA: 9s 14/18 [======================>.......] - ETA: 7s15/18 [========================>.....] - ETA: 5s16/18 [=========================>....] - ETA: 4s17/18 [===========================>..] - ETA: 2s18/18 [==============================] - ETA: 0s18/18 [==============================] - 37s 2s/step
fpr: [[0.0, 1.0], [0.0, 0.003067484662576687, 1.0]]
tpr: [[0.0, 1.0], [0.0, 0.024096385542168676, 1.0]]
roc_auc: [0.5, 0.510514450439796]
Round 3 - y_pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Round 3 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[  0 326]
 [  0 249]]
Precision: 0.1875
Recall: 0.4330
F1 score: 0.2617
 1/18 [>.............................] - ETA: 42s - loss: 11775.1348 - accuracy: 0.2500 2/18 [==>...........................] - ETA: 34s - loss: 12281.6875 - accuracy: 0.2188 3/18 [====>.........................] - ETA: 34s - loss: 12482.4297 - accuracy: 0.2083 4/18 [=====>........................] - ETA: 30s - loss: 12986.1719 - accuracy: 0.1719 5/18 [=======>......................] - ETA: 28s - loss: 12153.3369 - accuracy: 0.2250 6/18 [=========>....................] - ETA: 26s - loss: 12318.5049 - accuracy: 0.2135 7/18 [==========>...................] - ETA: 24s - loss: 12233.7393 - accuracy: 0.2188 8/18 [============>.................] - ETA: 22s - loss: 12011.0918 - accuracy: 0.2344 9/18 [==============>...............] - ETA: 19s - loss: 11997.9531 - accuracy: 0.236110/18 [===============>..............] - ETA: 17s - loss: 11997.6582 - accuracy: 0.234411/18 [=================>............] - ETA: 14s - loss: 12002.3398 - accuracy: 0.233012/18 [===================>..........] - ETA: 12s - loss: 11771.1631 - accuracy: 0.247413/18 [====================>.........] - ETA: 10s - loss: 11133.2979 - accuracy: 0.288514/18 [======================>.......] - ETA: 8s - loss: 10474.5684 - accuracy: 0.3304 15/18 [========================>.....] - ETA: 6s - loss: 9933.1826 - accuracy: 0.3646 16/18 [=========================>....] - ETA: 4s - loss: 9482.5088 - accuracy: 0.392617/18 [===========================>..] - ETA: 2s - loss: 9215.2715 - accuracy: 0.409918/18 [==============================] - ETA: 0s - loss: 8857.4326 - accuracy: 0.433018/18 [==============================] - 39s 2s/step - loss: 8857.4326 - accuracy: 0.4330
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-27 19:10:49,873 | server.py:125 | fit progress: (3, 8857.4326171875, {'accuracy': 0.4330434799194336}, 28703.754283252172)
DEBUG flwr 2023-09-27 19:10:49,874 | server.py:173 | evaluate_round 3: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 19:11:10,757 | server.py:187 | evaluate_round 3 received 4 results and 0 failures
DEBUG flwr 2023-09-27 19:11:10,758 | server.py:223 | fit_round 4: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 21:41:36,545 | server.py:237 | fit_round 4 received 4 results and 0 failures
Round 3 evaluation completed
 1/18 [>.............................] - ETA: 35s 2/18 [==>...........................] - ETA: 25s 3/18 [====>.........................] - ETA: 22s 4/18 [=====>........................] - ETA: 21s 5/18 [=======>......................] - ETA: 21s 6/18 [=========>....................] - ETA: 20s 7/18 [==========>...................] - ETA: 18s 8/18 [============>.................] - ETA: 17s 9/18 [==============>...............] - ETA: 15s10/18 [===============>..............] - ETA: 13s11/18 [=================>............] - ETA: 12s12/18 [===================>..........] - ETA: 10s13/18 [====================>.........] - ETA: 8s 14/18 [======================>.......] - ETA: 7s15/18 [========================>.....] - ETA: 5s16/18 [=========================>....] - ETA: 3s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 33s 2s/step
fpr: [[0.0, 0.024096385542168676, 1.0], [0.0, 1.0]]
tpr: [[0.0, 0.003067484662576687, 1.0], [0.0, 1.0]]
roc_auc: [0.489485549560204, 0.5]
Round 4 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 4 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 28s - loss: 10072.7480 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 25s - loss: 8851.6689 - accuracy: 0.7812  3/18 [====>.........................] - ETA: 26s - loss: 8542.4170 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 26s - loss: 7023.6113 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 25s - loss: 9052.6748 - accuracy: 0.7750 6/18 [=========>....................] - ETA: 22s - loss: 8595.4678 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 20s - loss: 8796.1465 - accuracy: 0.7812 8/18 [============>.................] - ETA: 17s - loss: 9450.0986 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 15s - loss: 9545.0508 - accuracy: 0.763910/18 [===============>..............] - ETA: 14s - loss: 9482.3770 - accuracy: 0.765611/18 [=================>............] - ETA: 12s - loss: 9448.2217 - accuracy: 0.767012/18 [===================>..........] - ETA: 10s - loss: 10011.7510 - accuracy: 0.752613/18 [====================>.........] - ETA: 8s - loss: 11640.7227 - accuracy: 0.7115 14/18 [======================>.......] - ETA: 6s - loss: 13359.8975 - accuracy: 0.669615/18 [========================>.....] - ETA: 5s - loss: 14733.1055 - accuracy: 0.635416/18 [=========================>....] - ETA: 3s - loss: 15877.4082 - accuracy: 0.607417/18 [===========================>..] - ETA: 1s - loss: 16538.9746 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 17456.0234 - accuracy: 0.567018/18 [==============================] - 31s 2s/step - loss: 17456.0234 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-27 21:42:51,930 | server.py:125 | fit progress: (4, 17456.0234375, {'accuracy': 0.5669565200805664}, 37825.81155077228)
DEBUG flwr 2023-09-27 21:42:51,931 | server.py:173 | evaluate_round 4: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 21:43:11,316 | server.py:187 | evaluate_round 4 received 4 results and 0 failures
DEBUG flwr 2023-09-27 21:43:11,316 | server.py:223 | fit_round 5: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 23:55:34,946 | server.py:237 | fit_round 5 received 4 results and 0 failures
Round 4 evaluation completed
 1/18 [>.............................] - ETA: 21s 2/18 [==>...........................] - ETA: 17s 3/18 [====>.........................] - ETA: 16s 4/18 [=====>........................] - ETA: 15s 5/18 [=======>......................] - ETA: 14s 6/18 [=========>....................] - ETA: 13s 7/18 [==========>...................] - ETA: 11s 8/18 [============>.................] - ETA: 10s 9/18 [==============>...............] - ETA: 9s 10/18 [===============>..............] - ETA: 8s11/18 [=================>............] - ETA: 7s12/18 [===================>..........] - ETA: 6s13/18 [====================>.........] - ETA: 5s14/18 [======================>.......] - ETA: 4s15/18 [========================>.....] - ETA: 3s16/18 [=========================>....] - ETA: 2s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 20s 1s/step
fpr: [[0.0, 1.0], [0.0, 0.003067484662576687, 1.0]]
tpr: [[0.0, 1.0], [0.0, 0.024096385542168676, 1.0]]
roc_auc: [0.5, 0.510514450439796]
Round 5 - y_pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Round 5 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[  0 326]
 [  0 249]]
Precision: 0.1875
Recall: 0.4330
F1 score: 0.2617
 1/18 [>.............................] - ETA: 22s - loss: 5912.7705 - accuracy: 0.2500 2/18 [==>...........................] - ETA: 18s - loss: 6192.1274 - accuracy: 0.2188 3/18 [====>.........................] - ETA: 16s - loss: 6297.0103 - accuracy: 0.2083 4/18 [=====>........................] - ETA: 15s - loss: 6562.7578 - accuracy: 0.1719 5/18 [=======>......................] - ETA: 14s - loss: 6158.1562 - accuracy: 0.2250 6/18 [=========>....................] - ETA: 13s - loss: 6235.6187 - accuracy: 0.2135 7/18 [==========>...................] - ETA: 12s - loss: 6206.9517 - accuracy: 0.2188 8/18 [============>.................] - ETA: 10s - loss: 6100.9438 - accuracy: 0.2344 9/18 [==============>...............] - ETA: 9s - loss: 6090.3340 - accuracy: 0.2361 10/18 [===============>..............] - ETA: 8s - loss: 6102.1987 - accuracy: 0.234411/18 [=================>............] - ETA: 7s - loss: 6112.4849 - accuracy: 0.233012/18 [===================>..........] - ETA: 6s - loss: 6001.2505 - accuracy: 0.247413/18 [====================>.........] - ETA: 5s - loss: 5675.4683 - accuracy: 0.288514/18 [======================>.......] - ETA: 4s - loss: 5341.5347 - accuracy: 0.330415/18 [========================>.....] - ETA: 3s - loss: 5065.3672 - accuracy: 0.364616/18 [=========================>....] - ETA: 2s - loss: 4840.2329 - accuracy: 0.392617/18 [===========================>..] - ETA: 1s - loss: 4709.4961 - accuracy: 0.409918/18 [==============================] - ETA: 0s - loss: 4526.7344 - accuracy: 0.433018/18 [==============================] - 20s 1s/step - loss: 4526.7344 - accuracy: 0.4330
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-27 23:56:17,644 | server.py:125 | fit progress: (5, 4526.734375, {'accuracy': 0.4330434799194336}, 45831.525500600226)
DEBUG flwr 2023-09-27 23:56:17,645 | server.py:173 | evaluate_round 5: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-27 23:56:32,674 | server.py:187 | evaluate_round 5 received 4 results and 0 failures
DEBUG flwr 2023-09-27 23:56:32,675 | server.py:223 | fit_round 6: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 02:00:38,438 | server.py:237 | fit_round 6 received 4 results and 0 failures
Round 5 evaluation completed
 1/18 [>.............................] - ETA: 20s 2/18 [==>...........................] - ETA: 17s 3/18 [====>.........................] - ETA: 16s 4/18 [=====>........................] - ETA: 15s 5/18 [=======>......................] - ETA: 14s 6/18 [=========>....................] - ETA: 13s 7/18 [==========>...................] - ETA: 12s 8/18 [============>.................] - ETA: 11s 9/18 [==============>...............] - ETA: 9s 10/18 [===============>..............] - ETA: 8s11/18 [=================>............] - ETA: 7s12/18 [===================>..........] - ETA: 6s13/18 [====================>.........] - ETA: 5s14/18 [======================>.......] - ETA: 4s15/18 [========================>.....] - ETA: 3s16/18 [=========================>....] - ETA: 2s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 20s 1s/step
fpr: [[0.0, 0.024096385542168676, 1.0], [0.0, 1.0]]
tpr: [[0.0, 0.003067484662576687, 1.0], [0.0, 1.0]]
roc_auc: [0.489485549560204, 0.5]
Round 6 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 6 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 22s - loss: 2451.5176 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 17s - loss: 2122.0901 - accuracy: 0.7812 3/18 [====>.........................] - ETA: 16s - loss: 2065.5000 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 14s - loss: 1694.8409 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 13s - loss: 2186.4700 - accuracy: 0.7750 6/18 [=========>....................] - ETA: 12s - loss: 2072.9004 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 11s - loss: 2113.5183 - accuracy: 0.7812 8/18 [============>.................] - ETA: 10s - loss: 2273.2227 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 9s - loss: 2304.2605 - accuracy: 0.7639 10/18 [===============>..............] - ETA: 8s - loss: 2296.6890 - accuracy: 0.765611/18 [=================>............] - ETA: 7s - loss: 2284.6807 - accuracy: 0.767012/18 [===================>..........] - ETA: 6s - loss: 2422.0437 - accuracy: 0.752613/18 [====================>.........] - ETA: 5s - loss: 2814.3643 - accuracy: 0.711514/18 [======================>.......] - ETA: 4s - loss: 3231.3430 - accuracy: 0.669615/18 [========================>.....] - ETA: 3s - loss: 3554.0854 - accuracy: 0.635416/18 [=========================>....] - ETA: 2s - loss: 3838.3765 - accuracy: 0.607417/18 [===========================>..] - ETA: 1s - loss: 3995.7578 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 4219.8262 - accuracy: 0.567018/18 [==============================] - 19s 1s/step - loss: 4219.8262 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-28 02:01:21,665 | server.py:125 | fit progress: (6, 4219.826171875, {'accuracy': 0.5669565200805664}, 53335.546266473364)
DEBUG flwr 2023-09-28 02:01:21,666 | server.py:173 | evaluate_round 6: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 02:01:36,098 | server.py:187 | evaluate_round 6 received 4 results and 0 failures
DEBUG flwr 2023-09-28 02:01:36,098 | server.py:223 | fit_round 7: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 04:05:42,186 | server.py:237 | fit_round 7 received 4 results and 0 failures
Round 6 evaluation completed
 1/18 [>.............................] - ETA: 20s 2/18 [==>...........................] - ETA: 19s 3/18 [====>.........................] - ETA: 17s 4/18 [=====>........................] - ETA: 16s 5/18 [=======>......................] - ETA: 15s 6/18 [=========>....................] - ETA: 13s 7/18 [==========>...................] - ETA: 12s 8/18 [============>.................] - ETA: 11s 9/18 [==============>...............] - ETA: 10s10/18 [===============>..............] - ETA: 8s 11/18 [=================>............] - ETA: 7s12/18 [===================>..........] - ETA: 6s13/18 [====================>.........] - ETA: 5s14/18 [======================>.......] - ETA: 4s15/18 [========================>.....] - ETA: 3s16/18 [=========================>....] - ETA: 2s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 20s 1s/step
fpr: [[0.0, 0.024096385542168676, 1.0], [0.0, 1.0]]
tpr: [[0.0, 0.003067484662576687, 1.0], [0.0, 1.0]]
roc_auc: [0.489485549560204, 0.5]
Round 7 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 7 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 21s - loss: 484.4520 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 17s - loss: 413.1752 - accuracy: 0.7812 3/18 [====>.........................] - ETA: 16s - loss: 417.5866 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 15s - loss: 341.5715 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 14s - loss: 435.5982 - accuracy: 0.7750 6/18 [=========>....................] - ETA: 12s - loss: 410.5414 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 11s - loss: 415.7386 - accuracy: 0.7812 8/18 [============>.................] - ETA: 11s - loss: 447.5096 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 10s - loss: 451.3321 - accuracy: 0.763910/18 [===============>..............] - ETA: 9s - loss: 449.2938 - accuracy: 0.7656 11/18 [=================>............] - ETA: 7s - loss: 445.9883 - accuracy: 0.767012/18 [===================>..........] - ETA: 6s - loss: 470.7765 - accuracy: 0.752613/18 [====================>.........] - ETA: 5s - loss: 545.7623 - accuracy: 0.711514/18 [======================>.......] - ETA: 4s - loss: 632.7661 - accuracy: 0.669615/18 [========================>.....] - ETA: 3s - loss: 691.9838 - accuracy: 0.635416/18 [=========================>....] - ETA: 2s - loss: 747.4578 - accuracy: 0.607417/18 [===========================>..] - ETA: 1s - loss: 778.0654 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 821.5647 - accuracy: 0.567018/18 [==============================] - 20s 1s/step - loss: 821.5647 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-28 04:06:26,398 | server.py:125 | fit progress: (7, 821.564697265625, {'accuracy': 0.5669565200805664}, 60840.27949572727)
DEBUG flwr 2023-09-28 04:06:26,399 | server.py:173 | evaluate_round 7: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 04:06:40,918 | server.py:187 | evaluate_round 7 received 4 results and 0 failures
DEBUG flwr 2023-09-28 04:06:40,918 | server.py:223 | fit_round 8: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 06:10:36,403 | server.py:237 | fit_round 8 received 4 results and 0 failures
Round 7 evaluation completed
 1/18 [>.............................] - ETA: 20s 2/18 [==>...........................] - ETA: 17s 3/18 [====>.........................] - ETA: 16s 4/18 [=====>........................] - ETA: 15s 5/18 [=======>......................] - ETA: 14s 6/18 [=========>....................] - ETA: 13s 7/18 [==========>...................] - ETA: 12s 8/18 [============>.................] - ETA: 11s 9/18 [==============>...............] - ETA: 9s 10/18 [===============>..............] - ETA: 8s11/18 [=================>............] - ETA: 7s12/18 [===================>..........] - ETA: 6s13/18 [====================>.........] - ETA: 5s14/18 [======================>.......] - ETA: 4s15/18 [========================>.....] - ETA: 3s16/18 [=========================>....] - ETA: 2s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 20s 1s/step
fpr: [[0.0, 0.024096385542168676, 1.0], [0.0, 1.0]]
tpr: [[0.0, 0.003067484662576687, 1.0], [0.0, 1.0]]
roc_auc: [0.489485549560204, 0.5]
Round 8 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 8 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 19s - loss: 933.7841 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 16s - loss: 798.5255 - accuracy: 0.7812 3/18 [====>.........................] - ETA: 15s - loss: 810.9767 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 14s - loss: 662.9114 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 13s - loss: 850.3175 - accuracy: 0.7750 6/18 [=========>....................] - ETA: 12s - loss: 805.2437 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 11s - loss: 811.9040 - accuracy: 0.7812 8/18 [============>.................] - ETA: 10s - loss: 874.1559 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 9s - loss: 883.3268 - accuracy: 0.7639 10/18 [===============>..............] - ETA: 8s - loss: 878.6864 - accuracy: 0.765611/18 [=================>............] - ETA: 7s - loss: 874.4693 - accuracy: 0.767012/18 [===================>..........] - ETA: 6s - loss: 926.4216 - accuracy: 0.752613/18 [====================>.........] - ETA: 5s - loss: 1074.1160 - accuracy: 0.711514/18 [======================>.......] - ETA: 4s - loss: 1243.0371 - accuracy: 0.669615/18 [========================>.....] - ETA: 3s - loss: 1362.0079 - accuracy: 0.635416/18 [=========================>....] - ETA: 2s - loss: 1470.5303 - accuracy: 0.607417/18 [===========================>..] - ETA: 1s - loss: 1531.6104 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 1618.6248 - accuracy: 0.567018/18 [==============================] - 19s 1s/step - loss: 1618.6248 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-28 06:11:19,479 | server.py:125 | fit progress: (8, 1618.624755859375, {'accuracy': 0.5669565200805664}, 68333.360248107)
DEBUG flwr 2023-09-28 06:11:19,479 | server.py:173 | evaluate_round 8: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 06:11:33,932 | server.py:187 | evaluate_round 8 received 4 results and 0 failures
DEBUG flwr 2023-09-28 06:11:33,933 | server.py:223 | fit_round 9: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 08:15:53,340 | server.py:237 | fit_round 9 received 4 results and 0 failures
Round 8 evaluation completed
 1/18 [>.............................] - ETA: 20s 2/18 [==>...........................] - ETA: 17s 3/18 [====>.........................] - ETA: 16s 4/18 [=====>........................] - ETA: 15s 5/18 [=======>......................] - ETA: 14s 6/18 [=========>....................] - ETA: 13s 7/18 [==========>...................] - ETA: 11s 8/18 [============>.................] - ETA: 10s 9/18 [==============>...............] - ETA: 9s 10/18 [===============>..............] - ETA: 8s11/18 [=================>............] - ETA: 7s12/18 [===================>..........] - ETA: 6s13/18 [====================>.........] - ETA: 5s14/18 [======================>.......] - ETA: 4s15/18 [========================>.....] - ETA: 3s16/18 [=========================>....] - ETA: 2s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 19s 1s/step
fpr: [[0.0, 0.024096385542168676, 1.0], [0.0, 1.0]]
tpr: [[0.0, 0.003067484662576687, 1.0], [0.0, 1.0]]
roc_auc: [0.489485549560204, 0.5]
Round 9 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 9 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 20s - loss: 1051.3696 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 17s - loss: 907.3057 - accuracy: 0.7812  3/18 [====>.........................] - ETA: 16s - loss: 934.0357 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 15s - loss: 766.8617 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 14s - loss: 977.8044 - accuracy: 0.7750 6/18 [=========>....................] - ETA: 13s - loss: 923.0159 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 12s - loss: 924.4680 - accuracy: 0.7812 8/18 [============>.................] - ETA: 11s - loss: 999.2203 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 9s - loss: 1012.1487 - accuracy: 0.763910/18 [===============>..............] - ETA: 8s - loss: 1005.9889 - accuracy: 0.765611/18 [=================>............] - ETA: 7s - loss: 999.1393 - accuracy: 0.7670 12/18 [===================>..........] - ETA: 6s - loss: 1059.1931 - accuracy: 0.752613/18 [====================>.........] - ETA: 5s - loss: 1228.6844 - accuracy: 0.711514/18 [======================>.......] - ETA: 4s - loss: 1434.4480 - accuracy: 0.669615/18 [========================>.....] - ETA: 3s - loss: 1563.1361 - accuracy: 0.635416/18 [=========================>....] - ETA: 2s - loss: 1686.5990 - accuracy: 0.607417/18 [===========================>..] - ETA: 1s - loss: 1753.5441 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 1857.5985 - accuracy: 0.567018/18 [==============================] - 20s 1s/step - loss: 1857.5985 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-28 08:16:35,985 | server.py:125 | fit progress: (9, 1857.5985107421875, {'accuracy': 0.5669565200805664}, 75849.86634760303)
DEBUG flwr 2023-09-28 08:16:35,986 | server.py:173 | evaluate_round 9: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 08:16:49,956 | server.py:187 | evaluate_round 9 received 4 results and 0 failures
DEBUG flwr 2023-09-28 08:16:49,956 | server.py:223 | fit_round 10: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 10:25:48,924 | server.py:237 | fit_round 10 received 4 results and 0 failures
Round 9 evaluation completed
 1/18 [>.............................] - ETA: 23s 2/18 [==>...........................] - ETA: 22s 3/18 [====>.........................] - ETA: 20s 4/18 [=====>........................] - ETA: 19s 5/18 [=======>......................] - ETA: 17s 6/18 [=========>....................] - ETA: 15s 7/18 [==========>...................] - ETA: 14s 8/18 [============>.................] - ETA: 13s 9/18 [==============>...............] - ETA: 11s10/18 [===============>..............] - ETA: 10s11/18 [=================>............] - ETA: 9s 12/18 [===================>..........] - ETA: 7s13/18 [====================>.........] - ETA: 6s14/18 [======================>.......] - ETA: 5s15/18 [========================>.....] - ETA: 3s16/18 [=========================>....] - ETA: 2s17/18 [===========================>..] - ETA: 1s18/18 [==============================] - ETA: 0s18/18 [==============================] - 23s 1s/step
fpr: [[0.0, 0.024096385542168676, 1.0, 1.0], [0.0, 0.003067484662576687, 1.0]]
tpr: [[0.0, 0.003067484662576687, 0.9969325153374233, 1.0], [0.0, 0.0, 1.0]]
roc_auc: [0.48798876487545273, 0.49846625766871167]
Round 10 - y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Round 10 - y_true: [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1
 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1
 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]
Confusion matrix:
[[326   0]
 [249   0]]
Precision: 0.3214
Recall: 0.5670
F1 score: 0.4103
 1/18 [>.............................] - ETA: 24s - loss: 879.9719 - accuracy: 0.7500 2/18 [==>...........................] - ETA: 20s - loss: 748.5428 - accuracy: 0.7812 3/18 [====>.........................] - ETA: 19s - loss: 811.5273 - accuracy: 0.7917 4/18 [=====>........................] - ETA: 18s - loss: 659.3583 - accuracy: 0.8281 5/18 [=======>......................] - ETA: 16s - loss: 820.1973 - accuracy: 0.7750 6/18 [=========>....................] - ETA: 15s - loss: 776.1064 - accuracy: 0.7865 7/18 [==========>...................] - ETA: 14s - loss: 776.8187 - accuracy: 0.7812 8/18 [============>.................] - ETA: 12s - loss: 845.9636 - accuracy: 0.7656 9/18 [==============>...............] - ETA: 11s - loss: 855.8492 - accuracy: 0.763910/18 [===============>..............] - ETA: 10s - loss: 847.8802 - accuracy: 0.765611/18 [=================>............] - ETA: 8s - loss: 846.5465 - accuracy: 0.7670 12/18 [===================>..........] - ETA: 7s - loss: 889.0212 - accuracy: 0.752613/18 [====================>.........] - ETA: 6s - loss: 1017.3350 - accuracy: 0.711514/18 [======================>.......] - ETA: 5s - loss: 1197.5619 - accuracy: 0.669615/18 [========================>.....] - ETA: 3s - loss: 1296.1692 - accuracy: 0.635416/18 [=========================>....] - ETA: 2s - loss: 1397.3748 - accuracy: 0.607417/18 [===========================>..] - ETA: 1s - loss: 1446.2275 - accuracy: 0.590118/18 [==============================] - ETA: 0s - loss: 1535.7883 - accuracy: 0.567018/18 [==============================] - 23s 1s/step - loss: 1535.7883 - accuracy: 0.5670
/home/dodiyaa/anaconda3/envs/thesis/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
INFO flwr 2023-09-28 10:26:38,713 | server.py:125 | fit progress: (10, 1535.788330078125, {'accuracy': 0.5669565200805664}, 83652.5942500853)
DEBUG flwr 2023-09-28 10:26:38,714 | server.py:173 | evaluate_round 10: strategy sampled 4 clients (out of 4)
DEBUG flwr 2023-09-28 10:26:54,652 | server.py:187 | evaluate_round 10 received 4 results and 0 failures
INFO flwr 2023-09-28 10:26:54,652 | server.py:147 | FL finished in 83668.53354919702
INFO flwr 2023-09-28 10:26:54,653 | app.py:218 | app_fit: losses_distributed [(1, 285.1430696491694), (2, 10645.34602646113), (3, 7730.735560201691), (4, 19195.415403908), (5, 3980.3152144941973), (6, 4667.351032709382), (7, 891.6720344833612), (8, 1748.7450751319561), (9, 2083.066723578195), (10, 1806.8020287157437)]
INFO flwr 2023-09-28 10:26:54,653 | app.py:219 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-09-28 10:26:54,653 | app.py:220 | app_fit: metrics_distributed {}
INFO flwr 2023-09-28 10:26:54,653 | app.py:221 | app_fit: losses_centralized [(0, 0.7433564066886902), (1, 328.82159423828125), (2, 9732.5849609375), (3, 8857.4326171875), (4, 17456.0234375), (5, 4526.734375), (6, 4219.826171875), (7, 821.564697265625), (8, 1618.624755859375), (9, 1857.5985107421875), (10, 1535.788330078125)]
INFO flwr 2023-09-28 10:26:54,653 | app.py:222 | app_fit: metrics_centralized {'accuracy': [(0, 0.4330434799194336), (1, 0.4330434799194336), (2, 0.5669565200805664), (3, 0.4330434799194336), (4, 0.5669565200805664), (5, 0.4330434799194336), (6, 0.5669565200805664), (7, 0.5669565200805664), (8, 0.5669565200805664), (9, 0.5669565200805664), (10, 0.5669565200805664)]}
Round 10 evaluation completed
